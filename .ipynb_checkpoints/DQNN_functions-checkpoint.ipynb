{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# math related packages\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import qutip as qt\n",
    "# further packages\n",
    "from time import time\n",
    "from random import sample\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partialTraceKeep(obj, keep): # generalisation of ptrace(), partial trace via \"to-keep\" list\n",
    "    # return partial trace:\n",
    "    res = obj;\n",
    "    if len(keep) != len(obj.dims[0]):\n",
    "        res = obj.ptrace(keep);\n",
    "    return res;\n",
    "\n",
    "def partialTraceRem(obj, rem): # partial trace via \"to-remove\" list\n",
    "    # prepare keep list\n",
    "    rem.sort(reverse=True)\n",
    "    keep = list(range(len(obj.dims[0])))\n",
    "    for x in rem:\n",
    "        keep.pop(x)\n",
    "    res = obj;\n",
    "    # return partial trace:\n",
    "    if len(keep) != len(obj.dims[0]):\n",
    "        res = obj.ptrace(keep);\n",
    "    return res;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swappedOp(obj, i, j):\n",
    "    if i==j: return obj\n",
    "    numberOfQubits = len(obj.dims[0])\n",
    "    permute = list(range(numberOfQubits))\n",
    "    permute[i], permute[j] = permute[j], permute[i]\n",
    "    return obj.permute(permute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensoredId(N):\n",
    "    \"\"\"not quite understanding why we need to overwrite the dims here\"\"\"\n",
    "    #Make Identity matrix\n",
    "    res = qt.qeye(2**N)\n",
    "    #Make dims list\n",
    "    dims = [2 for i in range(N)]\n",
    "    dims = [dims.copy(), dims.copy()]\n",
    "    res.dims = dims\n",
    "    #Return\n",
    "    return res\n",
    "\n",
    "# dims tells dimension of the respective Hilbert spaces\n",
    "\n",
    "def tensoredQubit0(N):\n",
    "    #Make Qubit matrix\n",
    "    res = qt.fock(2**N).proj() #for some reason ran faster than fock_dm(2**N) in tests\n",
    "    #Make dims list\n",
    "    dims = [2 for i in range(N)]\n",
    "    dims = [dims.copy(), dims.copy()]\n",
    "    res.dims = dims\n",
    "    #Return\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unitariesCopy(unitaries): # deep copyof a list of unitaries\n",
    "    newUnitaries = []\n",
    "    for layer in unitaries:\n",
    "        newLayer = []\n",
    "        for unitary in layer:\n",
    "            newLayer.append(unitary.copy())\n",
    "        newUnitaries.append(newLayer)\n",
    "    return newUnitaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"should be numpy.random not scipy.random\"\"\"\n",
    "\n",
    "def randomQubitUnitary(numQubits): # alternatively, use functions rand_unitary and rand_unitary_haar\n",
    "    dim = 2**numQubits\n",
    "    #Make unitary matrix\n",
    "    res = np.random.normal(size=(dim,dim)) + 1j * np.random.normal(size=(dim,dim))\n",
    "    res = sc.linalg.orth(res)\n",
    "    res = qt.Qobj(res)\n",
    "    #Make dims list\n",
    "    dims = [2 for i in range(numQubits)]\n",
    "    dims = [dims.copy(), dims.copy()]\n",
    "    res.dims = dims\n",
    "    #Return\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomQubitState(numQubits): # alternatively, use functions rand_ket and rand_ket_haar\n",
    "    dim = 2**numQubits\n",
    "    #Make normalized state\n",
    "    res = np.random.normal(size=(dim,1)) + 1j * np.random.normal(size=(dim,1))\n",
    "    res = (1/sc.linalg.norm(res)) * res\n",
    "    res = qt.Qobj(res)\n",
    "    #Make dims list\n",
    "    dims1 = [2 for i in range(numQubits)]\n",
    "    dims2 = [1 for i in range(numQubits)]\n",
    "    dims = [dims1, dims2]\n",
    "    res.dims = dims\n",
    "    #Return\n",
    "    return res\n",
    "\n",
    "def randomTrainingData(unitary, N): # generating training data based on a unitary\n",
    "    numQubits = len(unitary.dims[0])\n",
    "    trainingData=[]\n",
    "    #Create training data pairs\n",
    "    for i in range(N):\n",
    "        t = randomQubitState(numQubits)\n",
    "        ut = unitary*t\n",
    "        trainingData.append([t,ut])\n",
    "    #Return\n",
    "    return trainingData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomNetwork(qnnArch, numTrainingPairs):\n",
    "    assert qnnArch[0]==qnnArch[-1], \"Not a valid QNN-Architecture.\"\n",
    "    \n",
    "    #Create the targeted network unitary and corresponding training data\n",
    "    networkUnitary = randomQubitUnitary(qnnArch[-1])\n",
    "    networkTrainingData = randomTrainingData(networkUnitary, numTrainingPairs)\n",
    "    \n",
    "    #Create the initial random perceptron unitaries for the network\n",
    "    networkUnitaries = [[]]\n",
    "    for l in range(1, len(qnnArch)):\n",
    "        numInputQubits = qnnArch[l-1]\n",
    "        numOutputQubits = qnnArch[l]\n",
    "        \n",
    "        networkUnitaries.append([])\n",
    "        for j in range(numOutputQubits):\n",
    "            unitary = randomQubitUnitary(numInputQubits+1)\n",
    "            if numOutputQubits-1 != 0:\n",
    "                unitary = qt.tensor(randomQubitUnitary(numInputQubits+1), tensoredId(numOutputQubits-1))\n",
    "                unitary = swappedOp(unitary, numInputQubits, numInputQubits + j)\n",
    "            networkUnitaries[l].append(unitary)\n",
    "    \n",
    "    #Return\n",
    "    return (qnnArch, networkUnitaries, networkTrainingData, networkUnitary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def costFunction(trainingData, outputStates):\n",
    "    costSum = 0\n",
    "    for i in range(len(trainingData)):\n",
    "        costSum += trainingData[i][1].dag() * outputStates[i] * trainingData[i][1]\n",
    "\n",
    "    return costSum.tr()/len(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeLayerChannel(qnnArch, unitaries, l, inputState):\n",
    "    numInputQubits = qnnArch[l-1]\n",
    "    numOutputQubits = qnnArch[l]\n",
    "\n",
    "    #Tensor input state\n",
    "    state = qt.tensor(inputState, tensoredQubit0(numOutputQubits))\n",
    "\n",
    "    #Calculate layer unitary\n",
    "    layerUni = unitaries[l][0].copy()\n",
    "    for i in range(1, numOutputQubits):\n",
    "        layerUni = unitaries[l][i] * layerUni\n",
    "\n",
    "    #Multiply and tensor out input state\n",
    "    return partialTraceRem(layerUni * state * layerUni.dag(), list(range(numInputQubits)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeAdjointLayerChannel(qnnArch, unitaries, l, outputState):\n",
    "    numInputQubits = qnnArch[l-1]\n",
    "    numOutputQubits = qnnArch[l]\n",
    "    \n",
    "    #Prepare needed states\n",
    "    inputId = tensoredId(numInputQubits)\n",
    "    state1 = qt.tensor(inputId, tensoredQubit0(numOutputQubits))\n",
    "    state2 = qt.tensor(inputId, outputState)\n",
    "\n",
    "    #Calculate layer unitary\n",
    "    layerUni = unitaries[l][0].copy()\n",
    "    for i in range(1, numOutputQubits):\n",
    "        layerUni = unitaries[l][i] * layerUni\n",
    "    \n",
    "    #Multiply and tensor out output state\n",
    "\n",
    "    return partialTraceKeep(state1 * layerUni.dag() * state2 * layerUni, list(range(numInputQubits)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedforward(qnnArch, unitaries, trainingData):\n",
    "    storedStates = []\n",
    "    for x in range(len(trainingData)):\n",
    "        currentState = trainingData[x][0] * trainingData[x][0].dag()\n",
    "        layerwiseList = [currentState]\n",
    "        for l in range(1, len(qnnArch)):\n",
    "            currentState = makeLayerChannel(qnnArch, unitaries, l, currentState)\n",
    "            layerwiseList.append(currentState)\n",
    "        storedStates.append(layerwiseList)\n",
    "    return storedStates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeUpdateMatrix(qnnArch, unitaries, trainingData, storedStates, lda, ep, l, j):\n",
    "    numInputQubits = qnnArch[l-1]\n",
    "    \n",
    "    #Calculate the sum:\n",
    "    summ = 0\n",
    "    for x in range(len(trainingData)):\n",
    "        #Calculate the commutator\n",
    "        firstPart = updateMatrixFirstPart(qnnArch, unitaries, storedStates, l, j, x)\n",
    "        secondPart = updateMatrixSecondPart(qnnArch, unitaries, trainingData, l, j, x)\n",
    "        mat = qt.commutator(firstPart, secondPart)\n",
    "        \n",
    "        #Trace out the rest\n",
    "        keep = list(range(numInputQubits))\n",
    "        keep.append(numInputQubits + j)\n",
    "        mat = partialTraceKeep(mat, keep)\n",
    "        \n",
    "        #Add to sum\n",
    "        summ = summ + mat\n",
    "\n",
    "    #Calculate the update matrix from the sum\n",
    "    summ = (-ep * (2**numInputQubits)/(lda*len(trainingData))) * summ\n",
    "    return summ.expm()\n",
    "\n",
    "\n",
    "def updateMatrixFirstPart(qnnArch, unitaries, storedStates, l, j, x):\n",
    "    numInputQubits = qnnArch[l-1]\n",
    "    numOutputQubits = qnnArch[l]\n",
    "    \n",
    "    #Tensor input state\n",
    "    state = qt.tensor(storedStates[x][l-1], tensoredQubit0(numOutputQubits))\n",
    "    \n",
    "    #Calculate needed product unitary\n",
    "    productUni = unitaries[l][0]\n",
    "    for i in range(1, j+1):\n",
    "        productUni = unitaries[l][i] * productUni\n",
    "    \n",
    "    #Multiply\n",
    "    return productUni * state * productUni.dag()\n",
    "\n",
    "\n",
    "def updateMatrixSecondPart(qnnArch, unitaries, trainingData, l, j, x):\n",
    "    numInputQubits = qnnArch[l-1]\n",
    "    numOutputQubits = qnnArch[l]\n",
    "    \n",
    "    #Calculate sigma state\n",
    "    state = trainingData[x][1] * trainingData[x][1].dag()\n",
    "    for i in range(len(qnnArch)-1,l,-1):\n",
    "        state = makeAdjointLayerChannel(qnnArch, unitaries, i, state)\n",
    "    #Tensor sigma state\n",
    "    state = qt.tensor(tensoredId(numInputQubits), state)\n",
    "    \n",
    "    #Calculate needed product unitary\n",
    "    productUni = tensoredId(numInputQubits + numOutputQubits)\n",
    "    for i in range(j+1, numOutputQubits):\n",
    "        productUni = unitaries[l][i] * productUni\n",
    "        \n",
    "    #Multiply\n",
    "    return productUni.dag() * state * productUni\n",
    "\n",
    "\n",
    "def makeUpdateMatrixTensored(qnnArch, unitaries, lda, ep, trainingData, storedStates, l, j):\n",
    "    numInputQubits = qnnArch[l-1]\n",
    "    numOutputQubits = qnnArch[l]\n",
    "    \n",
    "    res = makeUpdateMatrix(qnnArch, unitaries, lda, ep, trainingData, storedStates, l, j)\n",
    "    if numOutputQubits-1 != 0:\n",
    "        res = qt.tensor(res, tensoredId(numOutputQubits-1))\n",
    "    return swappedOp(res, numInputQubits, numInputQubits + j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qnnTraining(qnnArch, initialUnitaries, trainingData, lda, ep, trainingRounds, alert=0):\n",
    "    \n",
    "    ### FEEDFORWARD    \n",
    "    #Feedforward for given unitaries\n",
    "    s = 0\n",
    "    currentUnitaries = initialUnitaries\n",
    "    storedStates = feedforward(qnnArch, currentUnitaries, trainingData)\n",
    "\n",
    "    #Cost calculation for given unitaries\n",
    "    outputStates = []\n",
    "    for k in range(len(storedStates)):\n",
    "        outputStates.append(storedStates[k][-1])\n",
    "    plotlist = [[s], [costFunction(trainingData, outputStates)]]\n",
    "    \n",
    "    #Optional\n",
    "    runtime = time()\n",
    "    \n",
    "    #Training of the Quantum Neural Network\n",
    "    for k in range(trainingRounds):\n",
    "        if alert>0 and k%alert==0: print(\"In training round \"+str(k))\n",
    "        \n",
    "        ### UPDATING\n",
    "        newUnitaries = unitariesCopy(currentUnitaries)\n",
    "        \n",
    "        #Loop over layers:\n",
    "        for l in range(1, len(qnnArch)):\n",
    "            numInputQubits = qnnArch[l-1]\n",
    "            numOutputQubits = qnnArch[l]\n",
    "            \n",
    "            #Loop over perceptrons\n",
    "            for j in range(numOutputQubits):\n",
    "                newUnitaries[l][j] = (makeUpdateMatrixTensored(qnnArch,currentUnitaries,trainingData,storedStates,lda,ep,l,j)* currentUnitaries[l][j])\n",
    "        \n",
    "        ### FEEDFORWARD\n",
    "        #Feedforward for given unitaries\n",
    "        s = s + ep\n",
    "        currentUnitaries = newUnitaries\n",
    "        storedStates = feedforward(qnnArch, currentUnitaries, trainingData)\n",
    "        \n",
    "        #Cost calculation for given unitaries\n",
    "        outputStates = []\n",
    "        for m in range(len(storedStates)):\n",
    "            outputStates.append(storedStates[m][-1])\n",
    "        plotlist[0].append(s)\n",
    "        plotlist[1].append(costFunction(trainingData, outputStates))\n",
    "    \n",
    "    #Optional\n",
    "    runtime = time() - runtime\n",
    "    print(\"Trained \"+str(trainingRounds)+\" rounds for a \"+str(qnnArch)+\" network and \"+str(len(trainingData))+\" training pairs in \"+str(round(runtime, 2))+\" seconds\")\n",
    "    \n",
    "    #Return\n",
    "    return [plotlist, currentUnitaries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boundRand(D, N, n):\n",
    "    return (n/N) + (N-n)/(N*D*(D+1)) * (D + min(n**2+1, D**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsetTrainingAvg(qnnArch, initialUnitaries, trainingData, lda, ep, trainingRounds, iterations, n, alertIt=0):\n",
    "    costpoints = []\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        if alertIt>0 and i%alertIt==0: print(\"n=\"+str(n)+\", i=\"+str(i))\n",
    "        \n",
    "        #Prepare subset for training\n",
    "        trainingSubset = sample(trainingData, n)\n",
    "        \n",
    "        #Train with the subset\n",
    "        learnedUnitaries = qnnTraining(qnnArch, initialUnitaries, trainingSubset, lda, ep, trainingRounds)[1]\n",
    "        storedStates = feedforward(qnnArch, learnedUnitaries, trainingData)\n",
    "        outputStates = []\n",
    "        for k in range(len(storedStates)):\n",
    "            outputStates.append(storedStates[k][-1])\n",
    "        \n",
    "        #Calculate cost with all training data\n",
    "        costpoints.append(costFunction(trainingData, outputStates))\n",
    "    \n",
    "    return sum(costpoints)/len(costpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noisyDataTraining(qnnArch, initialUnitaries, trainingData, noisyData, lda, ep, trainingRounds, numData, stepSize, alertP=0):\n",
    "    noisyDataPlot = [[], []]\n",
    "    \n",
    "    i = 0\n",
    "    while i <= numData:\n",
    "        if alertP>0: print(\"Currently at \"+str(i/numData)+\"% noisy data.\")\n",
    "        \n",
    "        #Prepare mixed data for traing\n",
    "        testData1 = sample(trainingData, numData - i)\n",
    "        testData2 = sample(noisyData, i)\n",
    "        if i==0: testData = testData1\n",
    "        elif i==numData: testData = testData2\n",
    "        else: testData = testData1 + testData2\n",
    "        \n",
    "        #Train with the mixed data\n",
    "        learnedUnitaries = qnnTraining(qnnArch, initialUnitaries, testData, lda, ep, trainingRounds)[1]\n",
    "        storedStates = feedforward(qnnArch, learnedUnitaries, trainingData)\n",
    "        outputStates = []\n",
    "        for k in range(len(storedStates)):\n",
    "            outputStates.append(storedStates[k][-1])\n",
    "        \n",
    "        #Calculate cost with the real training data\n",
    "        noisyDataPlot[0].append(i)\n",
    "        noisyDataPlot[1].append(costFunction(trainingData, outputStates))\n",
    "        \n",
    "        i += stepSize\n",
    "    \n",
    "    return noisyDataPlot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
